[
  {
    "objectID": "starter-analysis-exercise/starter-analysis-exercise.html",
    "href": "starter-analysis-exercise/starter-analysis-exercise.html",
    "title": "Installing package",
    "section": "",
    "text": "Installing package\n\n\nIn R Console type in Install.package (“dslabs”) DO NOT RUN IN QUARTO CAUSES ERROR WHEN RENDERING.\n\n\nload dslabs package\n\nlibrary(\"dslabs\")\n\nWarning: package 'dslabs' was built under R version 4.5.2\n\n\n\n\nTaking a look at data\n\nstr(gapminder)\n\n'data.frame':   10545 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  115.4 148.2 208 NA 59.9 ...\n $ life_expectancy : num  62.9 47.5 36 63 65.4 ...\n $ fertility       : num  6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ...\n $ population      : num  1636054 11124892 5270844 54681 20619075 ...\n $ gdp             : num  NA 1.38e+10 NA NA 1.08e+11 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 4 1 1 2 2 3 2 5 4 3 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 19 11 10 2 15 21 2 1 22 21 ...\n\n#Summary of data\nsummary(gapminder)\n\n                country           year      infant_mortality life_expectancy\n Albania            :   57   Min.   :1960   Min.   :  1.50   Min.   :13.20  \n Algeria            :   57   1st Qu.:1974   1st Qu.: 16.00   1st Qu.:57.50  \n Angola             :   57   Median :1988   Median : 41.50   Median :67.54  \n Antigua and Barbuda:   57   Mean   :1988   Mean   : 55.31   Mean   :64.81  \n Argentina          :   57   3rd Qu.:2002   3rd Qu.: 85.10   3rd Qu.:73.00  \n Armenia            :   57   Max.   :2016   Max.   :276.90   Max.   :83.90  \n (Other)            :10203                  NA's   :1453                    \n   fertility       population             gdp               continent   \n Min.   :0.840   Min.   :3.124e+04   Min.   :4.040e+07   Africa  :2907  \n 1st Qu.:2.200   1st Qu.:1.333e+06   1st Qu.:1.846e+09   Americas:2052  \n Median :3.750   Median :5.009e+06   Median :7.794e+09   Asia    :2679  \n Mean   :4.084   Mean   :2.701e+07   Mean   :1.480e+11   Europe  :2223  \n 3rd Qu.:6.000   3rd Qu.:1.523e+07   3rd Qu.:5.540e+10   Oceania : 684  \n Max.   :9.220   Max.   :1.376e+09   Max.   :1.174e+13                  \n NA's   :187     NA's   :185         NA's   :2972                       \n             region    \n Western Asia   :1026  \n Eastern Africa : 912  \n Western Africa : 912  \n Caribbean      : 741  \n South America  : 684  \n Southern Europe: 684  \n (Other)        :5586  \n\n# determine the type of object gapminder is\nclass(gapminder)\n\n[1] \"data.frame\"\n\n\n\n\nInstall tidyverse package\nInstall tidyverse in R console. Not directly into Quarto.\n\n\nAdding the dplyr that is part of tidyverse\n\nlibrary (dplyr)\n\nWarning: package 'dplyr' was built under R version 4.5.2\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n\nThis code creates a new dataset called africadata that contains all rows from gapminder where the continent is Africa, keeping all columns.\n\nafricadata &lt;- gapminder %&gt;%\n  filter(continent == \"Africa\")\n\n\n\nTo test if previous code worked\n\n# look at data\nstr(africadata)\n\n'data.frame':   2907 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n $ fertility       : num  7.65 7.32 6.28 6.62 6.29 6.95 5.65 6.89 5.84 6.25 ...\n $ population      : num  11124892 5270844 2431620 524029 4829291 ...\n $ gdp             : num  1.38e+10 NA 6.22e+08 1.24e+08 5.97e+08 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\n#Summary of data\nsummary(africadata)\n\n         country          year      infant_mortality life_expectancy\n Algeria     :  57   Min.   :1960   Min.   : 11.40   Min.   :13.20  \n Angola      :  57   1st Qu.:1974   1st Qu.: 62.20   1st Qu.:48.23  \n Benin       :  57   Median :1988   Median : 93.40   Median :53.98  \n Botswana    :  57   Mean   :1988   Mean   : 95.12   Mean   :54.38  \n Burkina Faso:  57   3rd Qu.:2002   3rd Qu.:124.70   3rd Qu.:60.10  \n Burundi     :  57   Max.   :2016   Max.   :237.40   Max.   :77.60  \n (Other)     :2565                  NA's   :226                     \n   fertility       population             gdp               continent   \n Min.   :1.500   Min.   :    41538   Min.   :4.659e+07   Africa  :2907  \n 1st Qu.:5.160   1st Qu.:  1605232   1st Qu.:8.373e+08   Americas:   0  \n Median :6.160   Median :  5570982   Median :2.448e+09   Asia    :   0  \n Mean   :5.851   Mean   : 12235961   Mean   :9.346e+09   Europe  :   0  \n 3rd Qu.:6.860   3rd Qu.: 13888152   3rd Qu.:6.552e+09   Oceania :   0  \n Max.   :8.450   Max.   :182201962   Max.   :1.935e+11                  \n NA's   :51      NA's   :51          NA's   :637                        \n                       region   \n Eastern Africa           :912  \n Western Africa           :912  \n Middle Africa            :456  \n Northern Africa          :342  \n Southern Africa          :285  \n Australia and New Zealand:  0  \n (Other)                  :  0  \n\n\n\n\nTo create two new objects/variables that contain infant_mortality and life_expectancy and one that contains only population and life_expectancy from africa data.\n\n# Only infant_mortality and life_expectancy\nAfrica_infant_life &lt;- africadata %&gt;% select(infant_mortality, life_expectancy)\n# Only population and life_expectancy\nAfrica_pop_life &lt;- africadata %&gt;% select(population, life_expectancy)\n\n\n\nTo test if previous code worked\n\n# look at data\nstr(Africa_infant_life)\n\n'data.frame':   2907 obs. of  2 variables:\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n\nstr(Africa_pop_life)\n\n'data.frame':   2907 obs. of  2 variables:\n $ population     : num  11124892 5270844 2431620 524029 4829291 ...\n $ life_expectancy: num  47.5 36 38.3 50.3 35.2 ...\n\n\n\n#Summary of data\nsummary(Africa_infant_life)\n\n infant_mortality life_expectancy\n Min.   : 11.40   Min.   :13.20  \n 1st Qu.: 62.20   1st Qu.:48.23  \n Median : 93.40   Median :53.98  \n Mean   : 95.12   Mean   :54.38  \n 3rd Qu.:124.70   3rd Qu.:60.10  \n Max.   :237.40   Max.   :77.60  \n NA's   :226                     \n\n\n\n#Summary of data\nsummary(Africa_pop_life)\n\n   population        life_expectancy\n Min.   :    41538   Min.   :13.20  \n 1st Qu.:  1605232   1st Qu.:48.23  \n Median :  5570982   Median :53.98  \n Mean   : 12235961   Mean   :54.38  \n 3rd Qu.: 13888152   3rd Qu.:60.10  \n Max.   :182201962   Max.   :77.60  \n NA's   :51                         \n\n\n\n\nLoading ggplot2 for plotting\n\nlibrary (ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.5.2\n\n\n\n\nInfant Mortality vs life Expectancy plot\n\nggplot(Africa_infant_life, aes(x = infant_mortality, y = life_expectancy)) +\n  geom_point(color = \"blue\", size = 2) +\n  labs(\n    x = \"Infant Mortality\",\n    y = \"Life Expectancy\",\n    title = \"Life Expectancy vs Infant Mortality\"\n  ) +\n  theme_minimal()\n\nWarning: Removed 226 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nLife expectancy vs population (log-scaled x-axis) plot\n\nggplot(Africa_pop_life, aes(x = population, y = life_expectancy)) +\n  geom_point(color = \"darkgreen\", size = 2) +\n  scale_x_log10() +  # log-scale for x-axis\n  labs(\n    x = \"Population (log scale)\",\n    y = \"Life Expectancy\",\n    title = \"Life Expectancy vs Population\"\n  ) +\n  theme_minimal()\n\nWarning: Removed 51 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nThe plot life expectancy vs population that has multiple overlapping sets seems to be from multiple differnt years of data collection.\n\n\nGet the unique years with missing infant_mortality data\n\nAfricainfant_missing_years &lt;- africadata %&gt;%\n  filter(is.na(infant_mortality)) %&gt;%  # keep rows with missing infant_mortality\n  distinct(year) %&gt;%                    # get unique years\n  arrange(year)                         #sort the years\n\nAfricainfant_missing_years\n\n   year\n1  1960\n2  1961\n3  1962\n4  1963\n5  1964\n6  1965\n7  1966\n8  1967\n9  1968\n10 1969\n11 1970\n12 1971\n13 1972\n14 1973\n15 1974\n16 1975\n17 1976\n18 1977\n19 1978\n20 1979\n21 1980\n22 1981\n23 2016\n\n\n\n\nExtracting 2000’s data from africadata.\n\nafrica_2000 &lt;- africadata %&gt;%\n  filter(year == 2000)\n\n\n\nChecking africa_2000\n\nstr(africa_2000)\n\n'data.frame':   51 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ infant_mortality: num  33.9 128.3 89.3 52.4 96.2 ...\n $ life_expectancy : num  73.3 52.3 57.2 47.6 52.6 46.7 54.3 68.4 45.3 51.5 ...\n $ fertility       : num  2.51 6.84 5.98 3.41 6.59 7.06 5.62 3.7 5.45 7.35 ...\n $ population      : num  31183658 15058638 6949366 1736579 11607944 ...\n $ gdp             : num  5.48e+10 9.13e+09 2.25e+09 5.63e+09 2.61e+09 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\nsummary(africa_2000)\n\n         country        year      infant_mortality life_expectancy\n Algeria     : 1   Min.   :2000   Min.   : 12.30   Min.   :37.60  \n Angola      : 1   1st Qu.:2000   1st Qu.: 60.80   1st Qu.:51.75  \n Benin       : 1   Median :2000   Median : 80.30   Median :54.30  \n Botswana    : 1   Mean   :2000   Mean   : 78.93   Mean   :56.36  \n Burkina Faso: 1   3rd Qu.:2000   3rd Qu.:103.30   3rd Qu.:60.00  \n Burundi     : 1   Max.   :2000   Max.   :143.30   Max.   :75.00  \n (Other)     :45                                                  \n   fertility       population             gdp               continent \n Min.   :1.990   Min.   :    81154   Min.   :2.019e+08   Africa  :51  \n 1st Qu.:4.150   1st Qu.:  2304687   1st Qu.:1.274e+09   Americas: 0  \n Median :5.550   Median :  8799165   Median :3.238e+09   Asia    : 0  \n Mean   :5.156   Mean   : 15659800   Mean   :1.155e+10   Europe  : 0  \n 3rd Qu.:5.960   3rd Qu.: 17391242   3rd Qu.:8.654e+09   Oceania : 0  \n Max.   :7.730   Max.   :122876723   Max.   :1.329e+11                \n                                                                      \n                       region  \n Eastern Africa           :16  \n Western Africa           :16  \n Middle Africa            : 8  \n Northern Africa          : 6  \n Southern Africa          : 5  \n Australia and New Zealand: 0  \n (Other)                  : 0  \n\n\n\n\nplot for africa 2000 life expectancy vs population\n\nggplot(africa_2000, aes(x = population, y = life_expectancy)) +\n  geom_point(color = \"darkgreen\", size = 2) +\n  scale_x_log10() +  # log-scale for x-axis\n  labs(\n    x = \"Population (log scale)\",\n    y = \"Life Expectancy\",\n    title = \"Life Expectancy vs Population\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nplot for africa 2000 Infant Mortality vs life Expectancy\n\nggplot(africa_2000, aes(x = infant_mortality, y = life_expectancy)) +\n  geom_point(color = \"blue\", size = 2) +\n  labs(\n    x = \"Infant Mortality\",\n    y = \"Life Expectancy\",\n    title = \"Life Expectancy vs Infant Mortality\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nRunning linear regression on life expectancy and infant mortality plot\n\n# Fit a linear model: life_expectancy ~ infant_mortality\nfit1 &lt;- lm(life_expectancy ~ infant_mortality, data = africa_2000)\n\n# Print a summary of the model\nsummary(fit1)\n\n\nCall:\nlm(formula = life_expectancy ~ infant_mortality, data = africa_2000)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.6651  -3.7087   0.9914   4.0408   8.6817 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      71.29331    2.42611  29.386  &lt; 2e-16 ***\ninfant_mortality -0.18916    0.02869  -6.594 2.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.221 on 49 degrees of freedom\nMultiple R-squared:  0.4701,    Adjusted R-squared:  0.4593 \nF-statistic: 43.48 on 1 and 49 DF,  p-value: 2.826e-08\n\n\n\n\nThis linear regression shows that there is a strong negative relationship between infant mortality and life expectancy among African countries in 2000.Higher infant mortality tend to have lower life expectancy, and this relationship is statistically significant.\n\n\nRunning linear regression on life expectancy vs population plot\n\n# Fit a linear model: life_expectancy ~ population\nfit2 &lt;- lm(life_expectancy ~ population, data = africa_2000)\n\n# Print a summary of the model\nsummary(fit2)\n\n\nCall:\nlm(formula = life_expectancy ~ population, data = africa_2000)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-18.429  -4.602  -2.568   3.800  18.802 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 5.593e+01  1.468e+00  38.097   &lt;2e-16 ***\npopulation  2.756e-08  5.459e-08   0.505    0.616    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.524 on 49 degrees of freedom\nMultiple R-squared:  0.005176,  Adjusted R-squared:  -0.01513 \nF-statistic: 0.2549 on 1 and 49 DF,  p-value: 0.6159\n\n\n\n\nUnlike infant mortality, population size is not a good predictor of life expectancy for African countries in 2000. Any apparent trend is likely just random variation.\n\n\nAI was used to help with coding I was less familar with.\n\n\nThis section below was contributed by Joe Dainis! Hi\n\n#Install and download dslabs package\n#install.packages(\"dslabs\")\nlibrary(\"dslabs\")\n\n#See overview of mouse weights data\nstr(mice_weights)\n\n'data.frame':   780 obs. of  7 variables:\n $ body_weight : num  27.6 23 28.7 32.6 28.6 ...\n $ bone_density: num  0.616 0.769 0.684 0.644 0.53 ...\n $ percent_fat : num  7.26 4.95 6.02 9.54 6.99 ...\n $ sex         : Factor w/ 2 levels \"F\",\"M\": 1 1 1 1 1 1 1 1 1 1 ...\n $ diet        : Factor w/ 2 levels \"chow\",\"hf\": 1 1 1 1 1 1 1 1 1 1 ...\n $ gen         : Factor w/ 5 levels \"4\",\"7\",\"8\",\"9\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ litter      : Factor w/ 2 levels \"1\",\"2\": 1 1 1 1 1 1 1 1 1 1 ...\n\n#Get summary of the mouse weights data\nsummary(mice_weights)\n\n  body_weight     bone_density     percent_fat     sex       diet     gen     \n Min.   :18.13   Min.   :0.2708   Min.   : 2.552   F:398   chow:394   4 : 97  \n 1st Qu.:28.09   1st Qu.:0.4888   1st Qu.: 5.566   M:382   hf  :386   7 :195  \n Median :32.98   Median :0.5643   Median : 8.276                      8 :193  \n Mean   :34.08   Mean   :0.5697   Mean   : 8.594                      9 : 97  \n 3rd Qu.:39.37   3rd Qu.:0.6373   3rd Qu.:10.926                      11:198  \n Max.   :65.15   Max.   :0.9980   Max.   :22.154                              \n                 NA's   :4        NA's   :4                                   \n litter \n 1:442  \n 2:338  \n        \n        \n        \n        \n        \n\n#Install and load dplyr package\n#install.packages(\"dplyr\")\nlibrary(\"dplyr\")\n\n#Assign female mice to femalemice and then overview their data\nfemalemice = subset(mice_weights, sex == \"F\")\nstr(femalemice)\n\n'data.frame':   398 obs. of  7 variables:\n $ body_weight : num  27.6 23 28.7 32.6 28.6 ...\n $ bone_density: num  0.616 0.769 0.684 0.644 0.53 ...\n $ percent_fat : num  7.26 4.95 6.02 9.54 6.99 ...\n $ sex         : Factor w/ 2 levels \"F\",\"M\": 1 1 1 1 1 1 1 1 1 1 ...\n $ diet        : Factor w/ 2 levels \"chow\",\"hf\": 1 1 1 1 1 1 1 1 1 1 ...\n $ gen         : Factor w/ 5 levels \"4\",\"7\",\"8\",\"9\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ litter      : Factor w/ 2 levels \"1\",\"2\": 1 1 1 1 1 1 1 1 1 1 ...\n\nsummary(femalemice)\n\n  body_weight     bone_density     percent_fat     sex       diet     gen     \n Min.   :18.13   Min.   :0.2708   Min.   : 2.766   F:398   chow:200   4 : 50  \n 1st Qu.:25.35   1st Qu.:0.4531   1st Qu.: 5.690   M:  0   hf  :198   7 : 98  \n Median :28.71   Median :0.5090   Median : 8.181                      8 :100  \n Mean   :29.76   Mean   :0.5186   Mean   : 8.683                      9 : 50  \n 3rd Qu.:33.21   3rd Qu.:0.5793   3rd Qu.:11.017                      11:100  \n Max.   :65.15   Max.   :0.8519   Max.   :22.154                              \n                 NA's   :1        NA's   :1                                   \n litter \n 1:224  \n 2:174  \n        \n        \n        \n        \n        \n\n#Assign male mice to malemice and then overview their data\nmalemice = subset(mice_weights, sex == \"M\")\nstr(malemice)\n\n'data.frame':   382 obs. of  7 variables:\n $ body_weight : num  47 31.1 37.2 27 36.1 ...\n $ bone_density: num  0.842 0.611 0.673 0.578 0.727 ...\n $ percent_fat : num  9.35 6.98 7.58 5.45 5.94 ...\n $ sex         : Factor w/ 2 levels \"F\",\"M\": 2 2 2 2 2 2 2 2 2 2 ...\n $ diet        : Factor w/ 2 levels \"chow\",\"hf\": 1 1 1 1 1 1 1 1 1 1 ...\n $ gen         : Factor w/ 5 levels \"4\",\"7\",\"8\",\"9\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ litter      : Factor w/ 2 levels \"1\",\"2\": 1 1 1 1 1 1 1 1 1 1 ...\n\nsummary(malemice)\n\n  body_weight     bone_density     percent_fat     sex       diet     gen    \n Min.   :23.62   Min.   :0.3977   Min.   : 2.552   F:  0   chow:194   4 :47  \n 1st Qu.:32.97   1st Qu.:0.5553   1st Qu.: 5.407   M:382   hf  :188   7 :97  \n Median :37.87   Median :0.6113   Median : 8.410                      8 :93  \n Mean   :38.58   Mean   :0.6233   Mean   : 8.502                      9 :47  \n 3rd Qu.:43.57   3rd Qu.:0.6799   3rd Qu.:10.814                      11:98  \n Max.   :61.15   Max.   :0.9980   Max.   :20.011                             \n                 NA's   :3        NA's   :3                                  \n litter \n 1:218  \n 2:164  \n        \n        \n        \n        \n        \n\n#Select Diet and percent_fat for male and female subset groups\nfemaledietfat = select(femalemice, c('percent_fat', 'diet', 'body_weight'))\nmaledietfat = select(malemice, c('percent_fat', 'diet', 'body_weight'))\n\n#See overview and summarize percent fat and diet for male versus female mice\nstr(femaledietfat)\n\n'data.frame':   398 obs. of  3 variables:\n $ percent_fat: num  7.26 4.95 6.02 9.54 6.99 ...\n $ diet       : Factor w/ 2 levels \"chow\",\"hf\": 1 1 1 1 1 1 1 1 1 1 ...\n $ body_weight: num  27.6 23 28.7 32.6 28.6 ...\n\nsummary(femaledietfat)\n\n  percent_fat       diet      body_weight   \n Min.   : 2.766   chow:200   Min.   :18.13  \n 1st Qu.: 5.690   hf  :198   1st Qu.:25.35  \n Median : 8.181              Median :28.71  \n Mean   : 8.683              Mean   :29.76  \n 3rd Qu.:11.017              3rd Qu.:33.21  \n Max.   :22.154              Max.   :65.15  \n NA's   :1                                  \n\nstr(maledietfat)\n\n'data.frame':   382 obs. of  3 variables:\n $ percent_fat: num  9.35 6.98 7.58 5.45 5.94 ...\n $ diet       : Factor w/ 2 levels \"chow\",\"hf\": 1 1 1 1 1 1 1 1 1 1 ...\n $ body_weight: num  47 31.1 37.2 27 36.1 ...\n\nsummary(maledietfat)\n\n  percent_fat       diet      body_weight   \n Min.   : 2.552   chow:194   Min.   :23.62  \n 1st Qu.: 5.407   hf  :188   1st Qu.:32.97  \n Median : 8.410              Median :37.87  \n Mean   : 8.502              Mean   :38.58  \n 3rd Qu.:10.814              3rd Qu.:43.57  \n Max.   :20.011              Max.   :61.15  \n NA's   :3                                  \n\n#Make a plot comparing percent fat in the different diets for male or female mice\n##Install ggplot2 to make plots\n#install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\n#Generate plot for female mice looking at diet influence on body weight\nggplot(data = femaledietfat, aes(x = diet, y = body_weight, color = diet)) + geom_violin() + stat_summary(fun.y=mean, geom=\"point\", color=\"pink\", size=4) + labs(title=\"Influence of Diet on Body Weight in Female Outbred Mice\", x = \"mouse diet\", y = \"body weight at 19 weeks of age\")\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n\n\n\n#Generate plot for male mice looking at diet influence on body weight\nggplot(data = maledietfat, aes(x = diet, y = body_weight, color = diet)) + geom_violin() + stat_summary(fun.y=mean, geom=\"point\", color=\"blue\", size=4) + labs(title=\"Influence of Diet on Body Weight in Male Outbred Mice\", x = \"mouse diet\", y = \"body weight at 19 weeks of age\")\n\n\n\n\n\n\n\n#Generate plot for female mice looking at diet influence on fat percent\nggplot(data = femaledietfat, aes(x = diet, y = percent_fat, color = diet)) + geom_violin() + stat_summary(fun.y=mean, geom=\"point\", color=\"pink\", size=4) + labs(title=\"Influence of Diet on Fat Percentage in Female Outbred Mice\", x = \"mouse diet\", y = \"percent fat\")\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_summary()`).\n\n\n\n\n\n\n\n\n#Generate plot for male mice looking at diet influence on fat percent\nggplot(data = maledietfat, aes(x = diet, y = percent_fat, color = diet)) + geom_violin() + stat_summary(fun.y=mean, geom=\"point\", color=\"blue\", size=4) + labs(title=\"Influence of Diet on Fat Percentage in Male Outbred Mice\", x = \"mouse diet\", y = \"percent fat\")\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_summary()`).\n\n\n\n\n\n\n\n\n#Fit a logistic model for diet as a predictor of body weight and fat percentage\n##Convert rank to a factor for the numeric diet for female and male\nfemaledietfat$diet &lt;- factor(femaledietfat$diet)\nfemaledietfat$diet &lt;- as.numeric(femaledietfat$diet)\nfemaledietfat &lt;- femaledietfat %&gt;%\n  mutate(binarydiet = diet - 1)\n\nmaledietfat$diet &lt;- factor(maledietfat$diet)\nmaledietfat$diet &lt;- as.numeric(maledietfat$diet)\nmaledietfat &lt;- maledietfat %&gt;%\n  mutate(binarydiet = diet - 1)\n##Fit the logistic regression model\nmylogitfembody &lt;- glm(binarydiet ~ body_weight, data=femaledietfat, family = \"binomial\")\nsummary(mylogitfembody)\n\n\nCall:\nglm(formula = binarydiet ~ body_weight, family = \"binomial\", \n    data = femaledietfat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.38033    0.58641  -5.764 8.19e-09 ***\nbody_weight  0.11397    0.01968   5.792 6.95e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 551.74  on 397  degrees of freedom\nResidual deviance: 511.07  on 396  degrees of freedom\nAIC: 515.07\n\nNumber of Fisher Scoring iterations: 4\n\nmylogitfemfat &lt;- glm(binarydiet ~ percent_fat, data=femaledietfat, family = \"binomial\")\nsummary(mylogitfemfat)\n\n\nCall:\nglm(formula = binarydiet ~ percent_fat, family = \"binomial\", \n    data = femaledietfat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.98306    0.34784  -8.576   &lt;2e-16 ***\npercent_fat  0.34921    0.03969   8.797   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 550.34  on 396  degrees of freedom\nResidual deviance: 439.45  on 395  degrees of freedom\n  (1 observation deleted due to missingness)\nAIC: 443.45\n\nNumber of Fisher Scoring iterations: 4\n\nmylogitmalebody &lt;- glm(binarydiet ~ body_weight, data=maledietfat, family = \"binomial\")\nsummary(mylogitmalebody)\n\n\nCall:\nglm(formula = binarydiet ~ body_weight, family = \"binomial\", \n    data = maledietfat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.08170    0.75017  -8.107 5.19e-16 ***\nbody_weight  0.15742    0.01939   8.118 4.75e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 529.47  on 381  degrees of freedom\nResidual deviance: 441.38  on 380  degrees of freedom\nAIC: 445.38\n\nNumber of Fisher Scoring iterations: 4\n\nmylogitmalefat &lt;- glm(binarydiet ~ percent_fat, data=maledietfat, family = \"binomial\")\nsummary(mylogitmalefat)\n\n\nCall:\nglm(formula = binarydiet ~ percent_fat, family = \"binomial\", \n    data = maledietfat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.88840    0.41779  -9.307   &lt;2e-16 ***\npercent_fat  0.45889    0.04831   9.498   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 525.19  on 378  degrees of freedom\nResidual deviance: 378.31  on 377  degrees of freedom\n  (3 observations deleted due to missingness)\nAIC: 382.31\n\nNumber of Fisher Scoring iterations: 5\n\n#In summary, we found that diet appears to have an influence in both male and female mice, with a high fat diet leading to a higher body weight at 19 weeks of age and a higher fat percentage. We also found that body weight and fat percentage of the mice can be a predictor of the diet that the mice was on."
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "Hi everyone! My name is Austin Hill. I’m from Jackson County, Georgia, and grew up near the city of Commerce. I completed my Bachelor of Science at the University of Georgia, majoring in Poultry Science with a minor in Avian Biology. During my undergraduate studies I gained hands on research experience at the USDA Southeastern Poultry Research Center, which sparked my interest in avian infectious diseases and applied research.\nAfter graduating, I was fortunate to be offered the opportunity to pursue a PhD with support from the USDA and my mentor at UGA, Dr. Grazieli Maboni. I am now in my third year of the Comparative Biomedical Sciences program, where my research focuses on avian reovirus adaptation, immunomodulatory effects, and vaccine development. When I’m not in the lab (which is rare), I enjoy playing basketball, cheering for the Dawgs, and going hiking. I also love exploring new restaurants around Athens and listening to a wide range of podcasts.\nHere is an image of my virus that I work with for my research!\n\nData Analysis Background\nSo far, the extent of my data analysis curriculum has been limited. I have taken courses like IDIS 8080L, which focused more on sequencing and biological analysis, and I recently completed BIOS 7010e, which I believe will be helpful for this class. I am particularly interested in taking this course because I hope to become more familiar with R and gain experience using analytical software that I can apply directly to my own research.\nFun Link!\nHere is a fun link to an Instagram page that has fun science humor, and even some data analysis memes."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Austin’s website and data analysis portfolio",
    "section": "",
    "text": "Welcome to my website and data analysis portfolio.\nPlease use the Menu Bar above to look around."
  },
  {
    "objectID": "data-exercise/starter-analysis-exercise.html",
    "href": "data-exercise/starter-analysis-exercise.html",
    "title": "Data exercise",
    "section": "",
    "text": "Data exercise\n\n\nOption 2: Synthetic Data Generation and Exploration\n\n\nAuthor: Austin Hill\n\n\nPurpose:\n\n\n1. Generate a synthetic dataset of individuals\n\n\n2. Build in a known association (height and NBA probability)\n\n\n3. Explore the data visually and with tables\n\n\n4. Fit simple models to recover the association\n\n\n\n# Load required libraries\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.2\n✔ purrr     1.2.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\n1. Generate Synthetic Data\n\n\n\n# Set a seed so results are reproducible\n# This ensures the same random data is created every time\nset.seed(123)\n\n\n# Number of individuals\nn &lt;- 100\n\n\n# Create a synthetic dataset\nsynthetic_data &lt;- tibble(\n  \n  # Height in feet:\n  # heights range from 5 to 7 feet\n  height_ft = runif(n, min = 5, max = 7),\n  \n  # NBA probability (0 to 1 initially):\n  # Taller people are made in this data to have a higher chance\n  # creating a linear relationship plus some random noise\n  nba_prob = 0.05 + 0.4 * (height_ft - 5) +   \n # height effect\nrnorm(n, mean = 0, sd = 0.05)\n)\n# Make sure probabilities stay between 0 and 1\nsynthetic_data &lt;- synthetic_data %&gt;%\n  mutate(\n    nba_prob = pmin(pmax(nba_prob, 0), 1),\n  # Convert probability to percentage (0–100)\n    nba_percent = nba_prob * 100\n  )\n\n\n# View the first few rows\nhead(synthetic_data)\n\n# A tibble: 6 × 3\n  height_ft nba_prob nba_percent\n      &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n1      5.58    0.293        29.3\n2      6.58    0.679        67.9\n3      5.82    0.375        37.5\n4      6.77    0.825        82.5\n5      6.88    0.791        79.1\n6      5.09    0.162        16.2\n\n\n\n\n\n\n\n\n2. Explore the Data with Tables\n\n\n\n# Summary statistics for height and NBA probability\nsummary(synthetic_data)\n\n   height_ft        nba_prob        nba_percent    \n Min.   :5.001   Min.   :0.02963   Min.   : 2.963  \n 1st Qu.:5.491   1st Qu.:0.26279   1st Qu.:26.279  \n Median :5.933   Median :0.43746   Median :43.746  \n Mean   :5.997   Mean   :0.44616   Mean   :44.616  \n 3rd Qu.:6.511   3rd Qu.:0.64710   3rd Qu.:64.710  \n Max.   :6.989   Max.   :0.91611   Max.   :91.611  \n\n\n\n# Create a simple table showing average NBA chance by height group\nsynthetic_data %&gt;%\n  mutate(\n    height_group = case_when(\n      height_ft &lt; 5.75 ~ \"Shorter\",\n      height_ft &lt; 6.5  ~ \"Medium\",\n      TRUE             ~ \"Taller\"\n       )\n  ) %&gt;%\n  group_by(height_group) %&gt;%\n  summarise(\n    avg_height = mean(height_ft),\n    avg_nba_percent = mean(nba_percent)\n  )\n\n# A tibble: 3 × 3\n  height_group avg_height avg_nba_percent\n  &lt;chr&gt;             &lt;dbl&gt;           &lt;dbl&gt;\n1 Medium             6.08            47.6\n2 Shorter            5.38            20.3\n3 Taller             6.72            74.0\n\n\n\n\n\n\n\n\n3. Visualize the Data with ggplot2\n\n\n\n# Scatter plot of height vs NBA probability\nggplot(synthetic_data, aes(x = height_ft, y = nba_percent)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    title = \"Height vs Chance of Making the NBA\",\n    x = \"Height (feet)\",\n    y = \"Chance of Making the NBA (%)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n# Histogram of height\nggplot(synthetic_data, aes(x = height_ft)) +\n  geom_histogram(bins = 20) +\n  labs(\n    title = \"Distribution of Height\",\n    x = \"Height (feet)\",\n    y = \"Person Count\"\n  )\n\n\n\n\n\n\n\n# Histogram of NBA probability\nggplot(synthetic_data, aes(x = nba_percent)) +\n  geom_histogram(bins = 20) +\n  labs(\n    title = \"Distribution of NBA Probability\",\n    x = \"Chance of Making the NBA (%)\",\n    y = \"Person Count\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4. Fit Simple Models\n\n\n\n# Linear model:\n# Predict NBA percentage using height\nlm_model &lt;- lm(nba_percent ~ height_ft, data = synthetic_data)\n# View model results\nsummary(lm_model)\n\n\nCall:\nlm(formula = nba_percent ~ height_ft, data = synthetic_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.1899  -3.0661  -0.0987   2.9817  11.0861 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -193.9219     5.1477  -37.67   &lt;2e-16 ***\nheight_ft     39.7754     0.8546   46.55   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.846 on 98 degrees of freedom\nMultiple R-squared:  0.9567,    Adjusted R-squared:  0.9563 \nF-statistic:  2166 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nInterpretation:\n\n\nThe coefficient for height_ft is positive,\n\n\nthis makes sense because I built the data so taller people have a higher chance.\n\n\n\n\n\n5. Logistic Model\n\n\n\n# Creating a binary outcome:\n# Did the person make the NBA? (Yes/No)\n# made it a 50/50 shot randomly generated using the prob. data \nsynthetic_data &lt;- synthetic_data %&gt;%\n  mutate(\n    made_nba = rbinom(n, size = 1, prob = nba_prob)\n  )\n\n# Fit a logistic regression model\nglm_model &lt;- glm(made_nba ~ height_ft,data = synthetic_data,family = binomial)\n\n# View model results\nsummary(glm_model)\n\n\nCall:\nglm(formula = made_nba ~ height_ft, family = binomial, data = synthetic_data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -11.0276     2.6279  -4.196 2.71e-05 ***\nheight_ft     1.8477     0.4377   4.221 2.43e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 138.59  on 99  degrees of freedom\nResidual deviance: 116.51  on 98  degrees of freedom\nAIC: 120.51\n\nNumber of Fisher Scoring iterations: 4\n\n# The Big Takeaway: Height Matters (A Lot) in making the NBA. \n\n\n\n\n\n\n\n6. Compare Model Fits\n\n\n\n# Plot predicted probabilities from the logistic model\nsynthetic_data %&gt;%\n  mutate(\n    predicted_prob = predict(glm_model, type = \"response\")\n  ) %&gt;%\n  ggplot(aes(x = height_ft, y = predicted_prob)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(\n    title = \"Predicted Probability of Making the NBA by Height\",\n    x = \"Height (feet)\",\n    y = \"Predicted Probability\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6. Compare Model Fits\n\n\n\n# Plot predicted probabilities from the logistic model\nsynthetic_data %&gt;%\n  mutate(\n    predicted_prob = predict(glm_model, type = \"response\")\n  ) %&gt;%\n  ggplot(aes(x = height_ft, y = predicted_prob)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(\n    title = \"Predicted Probability of Making the NBA by Height\",\n    x = \"Height (feet)\",\n    y = \"Predicted Probability\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Notes:\n\n\n- The linear model captures the overall trend\n\n\n- The logistic model is more appropriate for a yes/no outcome\n\n\n- Both models successfully recover the association that taller individuals have a higher chance of making the NBA\n\n\nDisclaimer: AI was used to assist with this excercise"
  },
  {
    "objectID": "data-exercise/data-exercise.html",
    "href": "data-exercise/data-exercise.html",
    "title": "Data exercise",
    "section": "",
    "text": "Data exercise\n\n\nOption 2: Synthetic Data Generation and Exploration\n\n\nAuthor: Austin Hill\n\n\nPurpose:\n\n\n1. Generate a synthetic dataset of individuals\n\n\n2. Build in a known association (height and NBA probability)\n\n\n3. Explore the data visually and with tables\n\n\n4. Fit simple models to recover the association\n\n\n\n# Load required libraries\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.2\n✔ purrr     1.2.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\n1. Generate Synthetic Data\n\n\n\n# Set a seed so results are reproducible\n# This ensures the same random data is created every time\nset.seed(123)\n\n\n# Number of individuals\nn &lt;- 100\n\n\n# Create a synthetic dataset\nsynthetic_data &lt;- tibble(\n  \n  # Height in feet:\n  # heights range from 5 to 7 feet\n  height_ft = runif(n, min = 5, max = 7),\n  \n  # NBA probability (0 to 1 initially):\n  # Taller people are made in this data to have a higher chance\n  # creating a linear relationship plus some random noise\n  nba_prob = 0.05 + 0.4 * (height_ft - 5) +   \n # height effect\nrnorm(n, mean = 0, sd = 0.05)\n)\n# Make sure probabilities stay between 0 and 1\nsynthetic_data &lt;- synthetic_data %&gt;%\n  mutate(\n    nba_prob = pmin(pmax(nba_prob, 0), 1),\n  # Convert probability to percentage (0–100)\n    nba_percent = nba_prob * 100\n  )\n\n\n# View the first few rows\nhead(synthetic_data)\n\n# A tibble: 6 × 3\n  height_ft nba_prob nba_percent\n      &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n1      5.58    0.293        29.3\n2      6.58    0.679        67.9\n3      5.82    0.375        37.5\n4      6.77    0.825        82.5\n5      6.88    0.791        79.1\n6      5.09    0.162        16.2\n\n\n\n\n\n\n\n\n2. Explore the Data with Tables\n\n\n\n# Summary statistics for height and NBA probability\nsummary(synthetic_data)\n\n   height_ft        nba_prob        nba_percent    \n Min.   :5.001   Min.   :0.02963   Min.   : 2.963  \n 1st Qu.:5.491   1st Qu.:0.26279   1st Qu.:26.279  \n Median :5.933   Median :0.43746   Median :43.746  \n Mean   :5.997   Mean   :0.44616   Mean   :44.616  \n 3rd Qu.:6.511   3rd Qu.:0.64710   3rd Qu.:64.710  \n Max.   :6.989   Max.   :0.91611   Max.   :91.611  \n\n\n\n# Create a simple table showing average NBA chance by height group\nsynthetic_data %&gt;%\n  mutate(\n    height_group = case_when(\n      height_ft &lt; 5.75 ~ \"Shorter\",\n      height_ft &lt; 6.5  ~ \"Medium\",\n      TRUE             ~ \"Taller\"\n       )\n  ) %&gt;%\n  group_by(height_group) %&gt;%\n  summarise(\n    avg_height = mean(height_ft),\n    avg_nba_percent = mean(nba_percent)\n  )\n\n# A tibble: 3 × 3\n  height_group avg_height avg_nba_percent\n  &lt;chr&gt;             &lt;dbl&gt;           &lt;dbl&gt;\n1 Medium             6.08            47.6\n2 Shorter            5.38            20.3\n3 Taller             6.72            74.0\n\n\n\n\n\n\n\n\n3. Visualize the Data with ggplot2\n\n\n\n# Scatter plot of height vs NBA probability\nggplot(synthetic_data, aes(x = height_ft, y = nba_percent)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    title = \"Height vs Chance of Making the NBA\",\n    x = \"Height (feet)\",\n    y = \"Chance of Making the NBA (%)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n# Histogram of height\nggplot(synthetic_data, aes(x = height_ft)) +\n  geom_histogram(bins = 20) +\n  labs(\n    title = \"Distribution of Height\",\n    x = \"Height (feet)\",\n    y = \"Person Count\"\n  )\n\n\n\n\n\n\n\n# Histogram of NBA probability\nggplot(synthetic_data, aes(x = nba_percent)) +\n  geom_histogram(bins = 20) +\n  labs(\n    title = \"Distribution of NBA Probability\",\n    x = \"Chance of Making the NBA (%)\",\n    y = \"Person Count\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4. Fit Simple Models\n\n\n\n# Linear model:\n# Predict NBA percentage using height\nlm_model &lt;- lm(nba_percent ~ height_ft, data = synthetic_data)\n# View model results\nsummary(lm_model)\n\n\nCall:\nlm(formula = nba_percent ~ height_ft, data = synthetic_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.1899  -3.0661  -0.0987   2.9817  11.0861 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -193.9219     5.1477  -37.67   &lt;2e-16 ***\nheight_ft     39.7754     0.8546   46.55   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.846 on 98 degrees of freedom\nMultiple R-squared:  0.9567,    Adjusted R-squared:  0.9563 \nF-statistic:  2166 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nInterpretation:\n\n\nThe coefficient for height_ft is positive,\n\n\nthis makes sense because I built the data so taller people have a higher chance.\n\n\n\n\n\n5. Logistic Model\n\n\n\n# Creating a binary outcome:\n# Did the person make the NBA? (Yes/No)\n# made it a 50/50 shot randomly generated using the prob. data \nsynthetic_data &lt;- synthetic_data %&gt;%\n  mutate(\n    made_nba = rbinom(n, size = 1, prob = nba_prob)\n  )\n\n# Fit a logistic regression model\nglm_model &lt;- glm(made_nba ~ height_ft,data = synthetic_data,family = binomial)\n\n# View model results\nsummary(glm_model)\n\n\nCall:\nglm(formula = made_nba ~ height_ft, family = binomial, data = synthetic_data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -11.0276     2.6279  -4.196 2.71e-05 ***\nheight_ft     1.8477     0.4377   4.221 2.43e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 138.59  on 99  degrees of freedom\nResidual deviance: 116.51  on 98  degrees of freedom\nAIC: 120.51\n\nNumber of Fisher Scoring iterations: 4\n\n# The Big Takeaway: Height Matters (A Lot) in making the NBA. \n\n\n\n\n\n\n\n6. Compare Model Fits\n\n\n\n# Plot predicted probabilities from the logistic model\nsynthetic_data %&gt;%\n  mutate(\n    predicted_prob = predict(glm_model, type = \"response\")\n  ) %&gt;%\n  ggplot(aes(x = height_ft, y = predicted_prob)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(\n    title = \"Predicted Probability of Making the NBA by Height\",\n    x = \"Height (feet)\",\n    y = \"Predicted Probability\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6. Compare Model Fits\n\n\n\n# Plot predicted probabilities from the logistic model\nsynthetic_data %&gt;%\n  mutate(\n    predicted_prob = predict(glm_model, type = \"response\")\n  ) %&gt;%\n  ggplot(aes(x = height_ft, y = predicted_prob)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(\n    title = \"Predicted Probability of Making the NBA by Height\",\n    x = \"Height (feet)\",\n    y = \"Predicted Probability\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Notes:\n\n\n- The linear model captures the overall trend\n\n\n- The logistic model is more appropriate for a yes/no outcome\n\n\n- Both models successfully recover the association that taller individuals have a higher chance of making the NBA\n\n\nDisclaimer: AI was used to assist with this excercise"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html",
    "href": "cdcdata-exercise/cdcdata-exercise.html",
    "title": "cdcdata-exercise",
    "section": "",
    "text": "Weekly Respiratory Syncytial Virus (RSV) Vaccination Coverage among Pregnant Women by Race and Ethnicity\nCitation: National Center for Immunization and Respiratory Diseases, US Centers for Disease Control and Prevention. Weekly RSV Vaccination Coverage, Pregnant Women 18-49 Years Old, By Race and Ethnicity, United States\nData Description: This dataset describes weekly RSV vaccination coverage among pregnant women ages 18–49 in the United States, as monitored by the National Center for Immunization and Respiratory Diseases (NCIRD) using data from the Vaccine Safety Datalink (VSD). The data begin in late September 2023, and track the proportion of eligible pregnant women who received the vaccine over time. Vaccination coverage is calculated using a denominator of pregnant women who reached at least 32 weeks of gestation since September 22, 2023, including some who may have been outside the recommended 32–36 week window. The numerator includes women who had received an RSV vaccine by each weekly reporting date.\nData Source: https://data.cdc.gov/Pregnancy-Vaccination/Weekly-Respiratory-Syncytial-Virus-RSV-Vaccination/g4jn-64pd/about_data\n# Load required packages\nlibrary(readr)    \nlibrary(dplyr)    \n\nWarning: package 'dplyr' was built under R version 4.5.2\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(lubridate) \n\nWarning: package 'lubridate' was built under R version 4.5.2\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(janitor)  \n\nWarning: package 'janitor' was built under R version 4.5.2\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.5.2\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.5.2\n# Read the data\nrsv_data &lt;- read_csv(\"Weekly_Respiratory_Syncytial_Virus_(RSV)_Vaccination_Coverage_among_Pregnant_Women_by_Race_and_Ethnicity_20260209.csv\")\n\nRows: 171 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Week_Ending_Date, Race and Ethnicity\ndbl (4): Percent, Date Order, Race Sort Order, Figure_ID\nnum (1): Denominator\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Preview the data \nhead(rsv_data)\n\n# A tibble: 6 × 7\n  Week_Ending_Date        `Race and Ethnicity`  Percent Denominator `Date Order`\n  &lt;chr&gt;                   &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1 2023 Sep 30 12:00:00 AM American Indian / Al…       0          49            1\n2 2023 Sep 30 12:00:00 AM Asian, NH                   0        2811            1\n3 2023 Sep 30 12:00:00 AM Black, NH                   0        1265            1\n4 2023 Sep 30 12:00:00 AM Hispanic/Latino             0        6809            1\n5 2023 Sep 30 12:00:00 AM Multiple/Other, NH          0         714            1\n6 2023 Sep 30 12:00:00 AM Native Hawaiian / Pa…       0         115            1\n# ℹ 2 more variables: `Race Sort Order` &lt;dbl&gt;, Figure_ID &lt;dbl&gt;\n\n# View the structure of the dataset (column names, types, example values)\nglimpse(rsv_data)\n\nRows: 171\nColumns: 7\n$ Week_Ending_Date     &lt;chr&gt; \"2023 Sep 30 12:00:00 AM\", \"2023 Sep 30 12:00:00 …\n$ `Race and Ethnicity` &lt;chr&gt; \"American Indian / Alaska Native, NH\", \"Asian, NH…\n$ Percent              &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,…\n$ Denominator          &lt;dbl&gt; 49, 2811, 1265, 6809, 714, 115, 18580, 815, 6002,…\n$ `Date Order`         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2…\n$ `Race Sort Order`    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8…\n$ Figure_ID            &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n\n# Look at the first few rows\nhead(rsv_data)\n\n# A tibble: 6 × 7\n  Week_Ending_Date        `Race and Ethnicity`  Percent Denominator `Date Order`\n  &lt;chr&gt;                   &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1 2023 Sep 30 12:00:00 AM American Indian / Al…       0          49            1\n2 2023 Sep 30 12:00:00 AM Asian, NH                   0        2811            1\n3 2023 Sep 30 12:00:00 AM Black, NH                   0        1265            1\n4 2023 Sep 30 12:00:00 AM Hispanic/Latino             0        6809            1\n5 2023 Sep 30 12:00:00 AM Multiple/Other, NH          0         714            1\n6 2023 Sep 30 12:00:00 AM Native Hawaiian / Pa…       0         115            1\n# ℹ 2 more variables: `Race Sort Order` &lt;dbl&gt;, Figure_ID &lt;dbl&gt;\n\n# Display column names explicitly\ncolnames(rsv_data)\n\n[1] \"Week_Ending_Date\"   \"Race and Ethnicity\" \"Percent\"           \n[4] \"Denominator\"        \"Date Order\"         \"Race Sort Order\"   \n[7] \"Figure_ID\"         \n\n# Generate basic summary statistics for each column\nsummary(rsv_data)\n\n Week_Ending_Date   Race and Ethnicity    Percent       Denominator     \n Length:171         Length:171         Min.   : 0.00   Min.   :   49.0  \n Class :character   Class :character   1st Qu.: 0.70   1st Qu.:  999.5  \n Mode  :character   Mode  :character   Median : 7.10   Median : 3292.0  \n                                       Mean   : 7.82   Mean   : 9731.1  \n                                       3rd Qu.:13.65   3rd Qu.:12082.5  \n                                       Max.   :24.80   Max.   :70519.0  \n   Date Order Race Sort Order   Figure_ID\n Min.   : 1   Min.   :1       Min.   :1  \n 1st Qu.: 5   1st Qu.:3       1st Qu.:1  \n Median :10   Median :5       Median :1  \n Mean   :10   Mean   :5       Mean   :1  \n 3rd Qu.:15   3rd Qu.:7       3rd Qu.:1  \n Max.   :19   Max.   :9       Max.   :1  \n\n# Count missing values in each column\ncolSums(is.na(rsv_data))\n\n  Week_Ending_Date Race and Ethnicity            Percent        Denominator \n                 0                  0                  0                  0 \n        Date Order    Race Sort Order          Figure_ID \n                 0                  0                  0\n# Convert column names to snake_case and remove spaces/special characters\n# This should make them easier to reference in code\nrsv_data &lt;- rsv_data %&gt;%\n  clean_names()\n# check data\nhead(rsv_data)\n\n# A tibble: 6 × 7\n  week_ending_date        race_and_ethnicity      percent denominator date_order\n  &lt;chr&gt;                   &lt;chr&gt;                     &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 2023 Sep 30 12:00:00 AM American Indian / Alas…       0          49          1\n2 2023 Sep 30 12:00:00 AM Asian, NH                     0        2811          1\n3 2023 Sep 30 12:00:00 AM Black, NH                     0        1265          1\n4 2023 Sep 30 12:00:00 AM Hispanic/Latino               0        6809          1\n5 2023 Sep 30 12:00:00 AM Multiple/Other, NH            0         714          1\n6 2023 Sep 30 12:00:00 AM Native Hawaiian / Paci…       0         115          1\n# ℹ 2 more variables: race_sort_order &lt;dbl&gt;, figure_id &lt;dbl&gt;\n# Convert the week_ending_date column from character text\n# (e.g., \"2023 Sep 30 12:00:00 AM\") to a datetime object\nSys.setlocale(\"LC_TIME\", \"C\")\n\n[1] \"C\"\n\nrsv_data &lt;- rsv_data %&gt;%\n  mutate(\n    week_ending_date = as.POSIXct(\n      week_ending_date,\n      format = \"%Y %b %d %I:%M:%S %p\",\n      tz = \"UTC\"\n    )\n  )\n# remove the time component and keep only the date\nrsv_data &lt;- rsv_data %&gt;%\n  mutate(\n    week_ending_date = as.Date(week_ending_date)\n  )\n  # check data \n  head(rsv_data)\n\n# A tibble: 6 × 7\n  week_ending_date race_and_ethnicity             percent denominator date_order\n  &lt;date&gt;           &lt;chr&gt;                            &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 2023-09-30       American Indian / Alaska Nati…       0          49          1\n2 2023-09-30       Asian, NH                            0        2811          1\n3 2023-09-30       Black, NH                            0        1265          1\n4 2023-09-30       Hispanic/Latino                      0        6809          1\n5 2023-09-30       Multiple/Other, NH                   0         714          1\n6 2023-09-30       Native Hawaiian / Pacific Isl…       0         115          1\n# ℹ 2 more variables: race_sort_order &lt;dbl&gt;, figure_id &lt;dbl&gt;\n# View unique race and ethnicity categories\n# helps identify inconsistencies or formatting issues\ndistinct(rsv_data, race_and_ethnicity)\n\n# A tibble: 9 × 1\n  race_and_ethnicity                    \n  &lt;chr&gt;                                 \n1 American Indian / Alaska Native, NH   \n2 Asian, NH                             \n3 Black, NH                             \n4 Hispanic/Latino                       \n5 Multiple/Other, NH                    \n6 Native Hawaiian / Pacific Islander, NH\n7 Overall                               \n8 Unknown                               \n9 White, NH                             \n\n# Trim extra whitespace and remove \"NH\" (Non-Hispanic)\n# NH does not add anything to the data set, I think it is not needed in the data set.\nrsv_data &lt;- rsv_data %&gt;%\n  mutate(\n    race_and_ethnicity = str_trim(race_and_ethnicity),\n    race_and_ethnicity = str_replace(race_and_ethnicity, \", NH$\", \"\")\n  )\n# check data\nhead(rsv_data)\n\n# A tibble: 6 × 7\n  week_ending_date race_and_ethnicity             percent denominator date_order\n  &lt;date&gt;           &lt;chr&gt;                            &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 2023-09-30       American Indian / Alaska Nati…       0          49          1\n2 2023-09-30       Asian                                0        2811          1\n3 2023-09-30       Black                                0        1265          1\n4 2023-09-30       Hispanic/Latino                      0        6809          1\n5 2023-09-30       Multiple/Other                       0         714          1\n6 2023-09-30       Native Hawaiian / Pacific Isl…       0         115          1\n# ℹ 2 more variables: race_sort_order &lt;dbl&gt;, figure_id &lt;dbl&gt;\n# Check the range of percent values to ensure they fall between 0 and 100\nrange(rsv_data$percent, na.rm = TRUE)\n\n[1]  0.0 24.8\n\n# Inspect rows where percent is zero\n# look to identifying early reporting periods or suppressed data\nrsv_data %&gt;%\n  filter(percent == 0) %&gt;%\n  count(week_ending_date)\n\n# A tibble: 5 × 2\n  week_ending_date     n\n  &lt;date&gt;           &lt;int&gt;\n1 2023-09-30           9\n2 2023-10-07           5\n3 2023-10-14           4\n4 2023-10-21           2\n5 2023-10-28           1\n\n# check data\nhead(rsv_data)\n\n# A tibble: 6 × 7\n  week_ending_date race_and_ethnicity             percent denominator date_order\n  &lt;date&gt;           &lt;chr&gt;                            &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 2023-09-30       American Indian / Alaska Nati…       0          49          1\n2 2023-09-30       Asian                                0        2811          1\n3 2023-09-30       Black                                0        1265          1\n4 2023-09-30       Hispanic/Latino                      0        6809          1\n5 2023-09-30       Multiple/Other                       0         714          1\n6 2023-09-30       Native Hawaiian / Pacific Isl…       0         115          1\n# ℹ 2 more variables: race_sort_order &lt;dbl&gt;, figure_id &lt;dbl&gt;\n# Check whether there are multiple rows for the same week and race/ethnicity combination\nrsv_data %&gt;%\n  count(week_ending_date, race_and_ethnicity) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 0 × 3\n# ℹ 3 variables: week_ending_date &lt;date&gt;, race_and_ethnicity &lt;chr&gt;, n &lt;int&gt;\n# Check how many unique values figure_id has\n# This column contains no useful information\nn_distinct(rsv_data$figure_id)\n\n[1] 1\n\n# Remove figure_id since it is constant across all rows\nrsv_data &lt;- rsv_data %&gt;%\n  select(-figure_id)\n# check data\nhead(rsv_data)\n\n# A tibble: 6 × 6\n  week_ending_date race_and_ethnicity             percent denominator date_order\n  &lt;date&gt;           &lt;chr&gt;                            &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 2023-09-30       American Indian / Alaska Nati…       0          49          1\n2 2023-09-30       Asian                                0        2811          1\n3 2023-09-30       Black                                0        1265          1\n4 2023-09-30       Hispanic/Latino                      0        6809          1\n5 2023-09-30       Multiple/Other                       0         714          1\n6 2023-09-30       Native Hawaiian / Pacific Isl…       0         115          1\n# ℹ 1 more variable: race_sort_order &lt;dbl&gt;\n# Get a overview of variable types\nglimpse(rsv_data)\n\nRows: 171\nColumns: 6\n$ week_ending_date   &lt;date&gt; 2023-09-30, 2023-09-30, 2023-09-30, 2023-09-30, 20…\n$ race_and_ethnicity &lt;chr&gt; \"American Indian / Alaska Native\", \"Asian\", \"Black\"…\n$ percent            &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0…\n$ denominator        &lt;dbl&gt; 49, 2811, 1265, 6809, 714, 115, 18580, 815, 6002, 5…\n$ date_order         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ race_sort_order    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, …\n# Count and percent by race/ethnicity\nrace_summary &lt;- rsv_data %&gt;%\n  count(race_and_ethnicity) %&gt;%\n  mutate(\n    percent = n / sum(n) * 100\n  ) %&gt;%\n  arrange(desc(percent))\n# This code is to see if observations are distributed evenly across racial and ethnic groups\nggplot(race_summary, aes(x = race_and_ethnicity, y = percent)) +\n  geom_col() +\n  labs(\n    title = \"Distribution of Observations by Race and Ethnicity\",\n    x = \"Race and Ethnicity\",\n    y = \"Percent of Observations\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n# Shows each group contributing a similar number of weekly observations over the study period\n# To see the data date range and total number of weeks\n\nrsv_data %&gt;%\n  summarise(\n    start_date = min(week_ending_date, na.rm = TRUE),\n    end_date   = max(week_ending_date, na.rm = TRUE),\n    n_weeks    = n_distinct(week_ending_date)\n  )\n\n# A tibble: 1 × 3\n  start_date end_date   n_weeks\n  &lt;date&gt;     &lt;date&gt;       &lt;int&gt;\n1 2023-09-30 2024-02-03      19\n# this code is to see if any weeks were skipped in the study with observations\nggplot(rsv_data, aes(x = week_ending_date)) +\n  geom_histogram(bins = 30) +\n  labs(\n    title = \"Distribution of Weekly Reporting Dates\",\n    x = \"Week Ending Date\",\n    y = \"Number of Observations\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n# the histogram confirms regular weekly reporting and no major gaps.\n# Distribution check of RSV vaccination coverage in a histogram\nggplot(rsv_data, aes(x = percent)) +\n  geom_histogram(bins = 30) +\n  labs(\n    title = \"Distribution of RSV Vaccination Coverage (%)\",\n    x = \"Vaccination Coverage (%)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n# Density check of RSV vaccination coverage\nggplot(rsv_data, aes(x = percent)) +\n  geom_density() +\n  labs(\n    title = \"Density of RSV Vaccination Coverage (%)\",\n    x = \"Vaccination Coverage (%)\",\n    y = \"Density\"\n  ) +\n  theme_minimal()\n# Numerical summary of percent vaccination coverage data\npercent_summary &lt;- rsv_data %&gt;%\n  summarise(\n    mean_percent = mean(percent, na.rm = TRUE),\n    sd_percent   = sd(percent, na.rm = TRUE),\n    min_percent  = min(percent, na.rm = TRUE),\n    max_percent  = max(percent, na.rm = TRUE)\n  )\n # Overall RSV vaccination coverage percentages appear approximately slightly skewed, with a mean of 7.82% and a standard deviation of 6.97%\n# Numerical summary of percent vaccination coverage data by Race/ethnicity \nrsv_data %&gt;%\n  group_by(race_and_ethnicity) %&gt;%\n  summarise(\n    mean_percent = mean(percent, na.rm = TRUE),\n    sd_percent   = sd(percent, na.rm = TRUE),\n    min_percent  = min(percent, na.rm = TRUE),\n    max_percent  = max(percent, na.rm = TRUE),\n    n            = n()\n  ) %&gt;%\n  arrange(desc(mean_percent))\n\n# A tibble: 9 × 6\n  race_and_ethnicity       mean_percent sd_percent min_percent max_percent     n\n  &lt;chr&gt;                           &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;int&gt;\n1 Asian                           11.2        9.83           0        24.8    19\n2 White                            9.34       7.59           0        19.9    19\n3 American Indian / Alask…         9.01       7.14           0        18.2    19\n4 Native Hawaiian / Pacif…         8.1        7.07           0        17.3    19\n5 Overall                          7.98       6.97           0        17.8    19\n6 Multiple/Other                   7.73       6.62           0        17.9    19\n7 Hispanic/Latino                  6.49       6.25           0        15.6    19\n8 Unknown                          6          4.71           0        12.6    19\n9 Black                            4.56       4.11           0        10.3    19\n# distribution of weekly total number of pregnant women (demoninator)\n# Count= Number of observations with that denominator size\nggplot(rsv_data, aes(x = denominator)) +\n  geom_histogram(bins = 30) +\n  labs(\n    title = \"Distribution of Weekly Denominators\",\n    x = \"Number of Pregnant Women\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n# as you can see this data is right skewed\n# Numerical summary of denominators data\nrsv_data %&gt;%\n  summarise(\n    mean_denom = mean(denominator, na.rm = TRUE),\n    sd_denom   = sd(denominator, na.rm = TRUE),\n    median_denom = median(denominator, na.rm = TRUE),\n    min_denom  = min(denominator, na.rm = TRUE),\n    max_denom  = max(denominator, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 5\n  mean_denom sd_denom median_denom min_denom max_denom\n       &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1      9731.   14517.         3292        49     70519\n# Vaccination coverage over time by race/ethnicity\nggplot(\n  rsv_data,\n  aes(\n    x = week_ending_date,\n    y = percent,\n    color = race_and_ethnicity\n  )\n) +\n  geom_line() +\n  labs(\n    title = \"Weekly RSV Vaccination Coverage by Race and Ethnicity\",\n    x = \"Date\",\n    y = \"Vaccination Coverage (%)\",\n    color = \"Race and Ethnicity\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n# Each line represents weekly RSV vaccination coverage for a specific race/ethnicity group, with colors distinguishing groups."
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#ai-prompt-used",
    "href": "cdcdata-exercise/cdcdata-exercise.html#ai-prompt-used",
    "title": "cdcdata-exercise",
    "section": "AI Prompt Used",
    "text": "AI Prompt Used\nWrite R code to generate a synthetic dataset with N = 171 observations that mimics a balanced weekly panel of RSV vaccination coverage by race/ethnicity. Create a dataframe named synthetic_data with the following columns: week_ending_date, race_and_ethnicity, percent, denominator, date_order, and race_sort_order. Use these assumptions based on the descriptive patterns: Panel structure / balance: There are 19 weekly dates (consecutive week-ending dates), and 9 race/ethnicity groups. Create an approximately balanced panel so that each week has about 9 observations (one per group), totaling 171 rows. Race_and_ethnicity: a categorical variable with 9 groups (e.g., American Indian/Alaska Native, Asian, Black, Hispanic/Latino, Multiple/Other, Native Hawaiian/Pacific Islander, Overall, Unknown, White). Keep group sizes roughly equal. Week_ending_date: weekly dates spanning about Oct to early Feb (19 weeks). date_order: an integer index 1–19 matching the chronological order of week_ending_date (repeat each value 9 times). Race_sort_order: an integer index 1–9 that assigns a fixed ordering to the race/ethnicity groups (repeat across weeks). percent (vaccination coverage): bounded to 0–25, with a strong upward time trend (near 0 in early weeks, increasing rapidly around mid-period, reaching roughly 10–25 by the end). Add group-specific offsets so groups diverge in later weeks. Ensure the distribution is right-skewed with many near-zero values (allow some exact zeros in early weeks). Denominator: a strictly positive count variable that is strongly right-skewed with a long tail (most values small, a few very large up to tens of thousands). Use a log-normal distribution (rounded to integers)."
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#code-for-synthetic-data",
    "href": "cdcdata-exercise/cdcdata-exercise.html#code-for-synthetic-data",
    "title": "cdcdata-exercise",
    "section": "Code for Synthetic Data",
    "text": "Code for Synthetic Data\n\nset.seed(20260211)\n\n# -----------------------------\n# 1) Panel structure\n# -----------------------------\nn_weeks  &lt;- 19\nn_groups &lt;- 9\n\nrace_levels &lt;- c(\n  \"American Indian/Alaska Native\",\n  \"Asian\",\n  \"Black\",\n  \"Hispanic/Latino\",\n  \"Multiple/Other\",\n  \"Native Hawaiian/Pacific Islander\",\n  \"Overall\",\n  \"Unknown\",\n  \"White\"\n)\n\nstart_date &lt;- as.Date(\"2025-10-04\")                 # week-ending date (e.g., Saturday)\nweek_dates &lt;- seq.Date(start_date, by = \"7 days\", length.out = n_weeks)\n\ndate_map &lt;- tibble(\n  week_ending_date = week_dates,\n  date_order       = 1:n_weeks\n)\n\nrace_map &lt;- tibble(\n  race_and_ethnicity = factor(race_levels, levels = race_levels),\n  race_sort_order    = 1:n_groups\n)\n\npanel &lt;- tidyr::expand_grid(\n  date_map, \n  race_map\n) %&gt;%\n  arrange(date_order, race_sort_order)\n\nstopifnot(nrow(panel) == 171)\n\n# -----------------------------\n# 2) Denominator: log-normal, long right tail (integers, strictly positive)\n# -----------------------------\ndenom_raw &lt;- rlnorm(n = nrow(panel), meanlog = 6.0, sdlog = 1.3)\ndenominator &lt;- pmax(1L, as.integer(round(denom_raw)))\n\n# -----------------------------\n# 3) Percent: bounded [0, 25], strong upward time trend, right-skew, many near-zero\n# -----------------------------\nt &lt;- panel$date_order\n\ntrend &lt;- 25 / (1 + exp(-0.65 * (t - 11)))  # logistic rise (0..~25)\n\ngroup_offsets &lt;- c(\n  `American Indian/Alaska Native`       = -1.8,\n  `Asian`                                =  2.0,\n  `Black`                                = -0.8,\n  `Hispanic/Latino`                      =  0.4,\n  `Multiple/Other`                       =  0.2,\n  `Native Hawaiian/Pacific Islander`     = -1.2,\n  `Overall`                              =  0.8,\n  `Unknown`                              = -2.5,\n  `White`                                =  1.4\n)\n\noffset_vec &lt;- unname(group_offsets[as.character(panel$race_and_ethnicity)])\ndiv_wt &lt;- (t / n_weeks)^1.7\n\nnoise_pos &lt;- rgamma(nrow(panel), shape = 0.8, scale = 1.2)  # right-skew\nnoise_sym &lt;- rnorm(nrow(panel), mean = 0, sd = 0.7)\n\n# more exact zeros early, fewer later\np_zero &lt;- plogis(-3.0 + 0.55 * (6 - t))\n\nbase &lt;- trend + div_wt * offset_vec + 0.7 * noise_pos + noise_sym\n\npercent &lt;- ifelse(runif(nrow(panel)) &lt; p_zero, 0, base)\npercent &lt;- pmin(25, pmax(0, percent))\npercent &lt;- round(percent, 1)\n\n# -----------------------------\n# 4) Final dataframe\n# -----------------------------\nsynthetic_data &lt;- panel %&gt;%\n  mutate(\n    percent = percent,\n    denominator = denominator\n  ) %&gt;%\n  select(\n    week_ending_date,\n    race_and_ethnicity,\n    percent,\n    denominator,\n    date_order,\n    race_sort_order\n  )"
  }
]